{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d49f9d2-30ea-4a9e-8bb1-a935f6af9d9c",
   "metadata": {},
   "source": [
    "# Local models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5254c8f4-a3a3-466d-9b50-a8e1d00dea1a",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ac947-b698-4c38-90c4-5deea6615645",
   "metadata": {},
   "source": [
    "**make sure you've 1. installed ollama, downloaded (pulled) the model, and started \"ollama serve\" as explained in the book!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c7d06c-9a02-417a-bfc3-df16f2def7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand why LangChain is considered great for working with LLMs. From what I know, LangChain is an open-source project that allows developers to create custom chatbots using language models like LLMs. It's built on PyTorch and provides a lot of flexibility.\n",
      "\n",
      "First, I remember that the user mentioned several key points about why LangChain is great. Let me go through each one step by step to make sure I understand them correctly.\n",
      "\n",
      "1. **Customizable Chatbot**: This makes sense because without a framework like LangChain, developers might struggle with structuring their chatbots. They can define how users interact with the model, set up rules for responses, and even customize the interface. It's more flexible than just using an LLM in isolation.\n",
      "\n",
      "2. **Extensive Model Library**: I think this refers to the variety of models available. LangChain includes a wide range from smaller models like GPT-3 to larger ones like BERT or T5. This diversity allows developers to experiment with different architectures and see which works best for their specific task, whether it's text generation, classification, or summarization.\n",
      "\n",
      "3. **Integration with PyTorch**: Since LangChain is built on PyTorch, it leverages the powerful deep learning frameworks that are already well-established. This integration means developers can easily use pre-trained models, fine-tune them for their needs, and access a wealth of resources available in PyTorch.\n",
      "\n",
      "4. **Extensive Documentation and Community Support**: Developers often face challenges when working with LLMs, so having comprehensive documentation is crucial. It helps troubleshoot issues, learn best practices, and find solutions quickly. The community aspect means there's a lot of support available if you run into problems or have questions about specific tasks.\n",
      "\n",
      "5. **Customizable Training Data**: This point is interesting because training an LLM can be time-consuming and requires large datasets. LangChain allows developers to train models on their own data, which saves time and resources. It also gives them control over the training process, enabling them to optimize parameters for better performance.\n",
      "\n",
      "6. **Real-time Interactions**: Chatbots are meant to interact with users in real-time. LangChain's design ensures that this is possible by providing a user-friendly interface where the model can respond immediately. This real-time capability makes chatbots more practical and effective for applications like customer service, content creation, or decision-making.\n",
      "\n",
      "7. **Extensive Evaluation Metrics**: Evaluating how well an LLM performs isn't just about accuracy; it's also about understanding the context in which the model was used. LangChain offers various metrics that help developers assess both the quality of responses and the relevance of the information provided. This makes it easier to fine-tune models based on specific needs.\n",
      "\n",
      "8. **Extensive Testing Infrastructure**: Ensuring that an LLM works correctly is crucial, especially when dealing with sensitive applications. LangChain's testing infrastructure includes tools for evaluating performance, monitoring interactions, and debugging issues. This ensures reliability and helps developers understand how their chatbots perform over time.\n",
      "\n",
      "9. **Extensive API Support**: Developers often need to integrate models into other systems or applications. LangChain provides APIs that allow them to access the model programmatically. These APIs are designed to be flexible, allowing for easy integration with various platforms while maintaining consistency in how models respond.\n",
      "\n",
      "10. **Extensive Community and Ecosystem**: Being part of a larger community means there's a wealth of resources available. Developers can find tutorials, examples, and best practices from others who have successfully used LangChain or similar frameworks. This collaborative environment fosters innovation and provides support when issues arise.\n",
      "\n",
      "Putting it all together, LangChain is great because it offers flexibility, customization, and a robust ecosystem that supports various tasks involving LLMs. It's built on powerful technologies, has extensive resources, and a strong community to help developers succeed. Plus, the real-time capabilities make it practical for many applications where immediate interaction is needed.\n",
      "\n",
      "I think I've covered all the key points, but maybe I missed something. Let me double-check each point against what I know about LangChain. Yes, that seems comprehensive. The main reasons are customization, model diversity, integration with PyTorch, documentation and community support, real-time features, evaluation metrics, testing infrastructure, API support, a strong community, and an ecosystem of resources.\n",
      "\n",
      "I should also consider if there's anything else that makes LangChain stand out. Maybe its open-source nature or the specific tools it provides? But from what I gather, these are all significant factors contributing to its success in the domain.\n",
      "</think>\n",
      "\n",
      "LangChain is considered great for working with LLMs due to several key reasons:\n",
      "\n",
      "1. **Customizable Chatbot**: It allows developers to create tailored chatbots by defining user interactions and response rules, offering flexibility beyond isolated model use.\n",
      "\n",
      "2. **Extensive Model Library**: LangChain includes a wide range of models from small to large architectures, enabling experimentation with different architectures for optimal performance on specific tasks.\n",
      "\n",
      "3. **Integration with PyTorch**: Leveraging PyTorch's deep learning tools provides access to powerful resources and frameworks already established in the community.\n",
      "\n",
      "4. **Extensive Documentation and Community Support**: Comprehensive documentation aids troubleshooting, while a strong community offers support and knowledge, facilitating rapid learning and problem-solving.\n",
      "\n",
      "5. **Customizable Training Data**: Developers can train models on their own datasets, saving time and resources compared to large-scale training.\n",
      "\n",
      "6. **Real-time Interactions**: The chatbot interface ensures immediate responses, making it practical for applications like customer service or content creation.\n",
      "\n",
      "7. **Extensive Evaluation Metrics**: Metrics assess response quality and context relevance, helping developers fine-tune models based on specific needs.\n",
      "\n",
      "8. **Extensive Testing Infrastructure**: Rigorous testing ensures reliability, with tools for performance evaluation and monitoring interactions.\n",
      "\n",
      "9. **Extensive API Support**: Developers can integrate models programmatically, facilitating integration into various platforms while maintaining consistency in responses.\n",
      "\n",
      "10. **Extensive Community and Ecosystem**: The community provides resources, tutorials, and best practices, fostering innovation and support when issues arise.\n",
      "\n",
      "LangChain's flexibility, customization, and robust ecosystem make it a powerful tool for developers working with LLMs, offering both practical applications and extensive resources to facilitate success.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant.\",\n",
    "    ),\n",
    "    (\"human\", \"What makes LangChain great for working with LLMs?\"),\n",
    "]\n",
    "ai_msg = chat.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1e2c7-674d-4b44-8cab-ac44db0e595f",
   "metadata": {},
   "source": [
    "## Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7b3d56-7ad8-47c9-b1fe-837cd78327c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You're a helpful assistant</s>\n",
      "<|user|>\n",
      "Explain the concept of machine learning in simple terms</s>\n",
      "<|assistant|>\n",
      "Machine learning is a field that involves the use of algorithms and data to learn from and improve upon the behavior of machines or systems. It is a powerful tool for automating tasks and improving the performance of systems by learning from data and making predictions based on that data.\n",
      "\n",
      "In simple terms, machine learning is the process of using algorithms to analyze and learn from data. This process involves collecting large amounts of data, training the algorithm to identify patterns and relationships in that data, and then using that knowledge to make predictions or make decisions.\n",
      "\n",
      "For example, a machine learning algorithm might be used to predict the likelihood of a customer purchasing a particular product based on their previous purchase history and other factors. Or it might be used to recommend products to a user based on their browsing and purchase history.\n",
      "\n",
      "Machine learning can be applied to a wide range of applications, from financial services to healthcare to transportation. It has the potential to revolutionize many industries by improving efficiency, reducing costs, and enabling new levels of personalization and customization.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "# Create a pipeline with a small model:\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    ),\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# Use it like any other LangChain LLM\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(\n",
    "        content=\"Explain the concept of machine learning in simple terms\"\n",
    "    ),\n",
    "]\n",
    "ai_msg = chat_model.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32cdc2-ba1b-47f5-94d6-6b00a2c1e26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
