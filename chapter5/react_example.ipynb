{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sNjI6aGKBzAJ0aIcO0YDYpWs",
      "metadata": {
        "id": "sNjI6aGKBzAJ0aIcO0YDYpWs",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatVertexAI(model=\"gemini-2.0-flash-001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1GKNegsPzgCs",
      "metadata": {
        "id": "1GKNegsPzgCs"
      },
      "source": [
        "# ReACT example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edec533f",
      "metadata": {},
      "source": [
        "Let's deep dive into the ReACT pattern and implement it ourselves. We will mock tools as simple Python functions (without actual implementation) for now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_v7ovZSy2JBD",
      "metadata": {
        "id": "_v7ovZSy2JBD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def mocked_google_search(query: str) -> str:\n",
        "  print(f\"CALLED GOOGLE_SEARCH with query={query}\")\n",
        "  return \"Donald Trump is a president of USA and he's 78 years old\"\n",
        "\n",
        "def mocked_calculator(expression: str) -> float:\n",
        "  print(f\"CALLED CALCULATOR with expression={expression}\")\n",
        "  if \"sqrt\" in expression:\n",
        "    return math.sqrt(78*132)\n",
        "  return 78*132"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c9c2a0",
      "metadata": {},
      "source": [
        "Let's define schemas for our tools and pass them to an LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iK3DLt6tA6e0",
      "metadata": {
        "id": "iK3DLt6tA6e0"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "calculator_tool = {\n",
        "   \"title\": \"calculator\",\n",
        "    \"description\": \"Computes mathematical expressions\",\n",
        "   \"type\": \"object\",\n",
        "   \"properties\": {\n",
        "       \"expression\": {\n",
        "           \"description\": \"A mathematical expression to be evaluated by a calculator\",\n",
        "           \"title\": \"expression\",\n",
        "           \"type\": \"string\"},\n",
        "   },\n",
        "   \"required\": [\"expression\"]\n",
        "}\n",
        "\n",
        "search_tool = {\n",
        "    \"description\": \"Returns about common facts, fresh events and news from Google Search engine based on a query.\",\n",
        "    \"title\": \"google_search\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"query\": {\n",
        "            \"description\": \"Search query to be sent to the search engine\",\n",
        "            \"title\": \"search_query\",\n",
        "            \"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"query\"]\n",
        "}\n",
        "\n",
        "system_prompt = (\n",
        "    \"Always use a calculator for mathematical computations, and use Google Search \"\n",
        "    \"for information about common facts, fresh events and news. Do not assume anything, keep in \"\n",
        "    \"mind that things are changing and always \"\n",
        "    \"check yourself with external sources if possible.\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    MessagesPlaceholder(variable_name=\"messages\"),\n",
        "])\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind(tools=[search_tool, calculator_tool]).bind(prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "361caf3e",
      "metadata": {},
      "source": [
        "Now it's time to define the LangGraph workflow itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cy95GSiLzhiA",
      "metadata": {
        "id": "Cy95GSiLzhiA"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "from langgraph.graph import MessagesState, StateGraph, START, END\n",
        "\n",
        "\n",
        "def invoke_llm(state: MessagesState):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "def call_tools(state: MessagesState):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    tool_calls = last_message.tool_calls\n",
        "\n",
        "    new_messages = []\n",
        "\n",
        "    for tool_call in tool_calls:\n",
        "      if tool_call[\"name\"] == \"google_search\":\n",
        "        tool_result = mocked_google_search(**tool_call[\"args\"])\n",
        "        new_messages.append(ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"]))\n",
        "      elif tool_call[\"name\"] == \"calculator\":\n",
        "        tool_result = mocked_calculator(**tool_call[\"args\"])\n",
        "        new_messages.append(ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"]))\n",
        "      else:\n",
        "        raise ValueError(f\"Tool {tool_call['name']} is not defined!\")\n",
        "    return {\"messages\": new_messages}\n",
        "\n",
        "\n",
        "def should_run_tools(state: MessagesState):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if last_message.tool_calls:\n",
        "      return \"call_tools\"\n",
        "    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758fc223",
      "metadata": {},
      "source": [
        "And we can put everything together as following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TQhNe5Oi1iJ8",
      "metadata": {
        "id": "TQhNe5Oi1iJ8"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"invoke_llm\", invoke_llm)\n",
        "builder.add_node(\"call_tools\", call_tools)\n",
        "\n",
        "builder.add_edge(START, \"invoke_llm\")\n",
        "builder.add_conditional_edges(\"invoke_llm\", should_run_tools)\n",
        "builder.add_edge(\"call_tools\", \"invoke_llm\")\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NBpFQ8-I2-xU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2933,
          "status": "ok",
          "timestamp": 1738242542414,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "NBpFQ8-I2-xU",
        "outputId": "bb4cae74-84e2-4168-ea0f-3edee8201f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CALLED GOOGLE_SEARCH with query=age of Joe Biden\n",
            "CALLED CALCULATOR with expression=sqrt(78 * 132)\n",
            "The square root of the current US president’s age multiplied by 132 is approximately 101.47.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question = \"What is a square root of the current US president’s age multiplied by 132?\"\n",
        "\n",
        "result = graph.invoke({\"messages\": [HumanMessage(content=question)]})\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3af963e9",
      "metadata": {},
      "source": [
        "Now as you understand how it works under the hood, we can share good news with you. There's no need to implement it yourselves, you can use an customizable pre-built agent from LangGraph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHvnnNh_DwNP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 306,
          "status": "ok",
          "timestamp": 1738238072999,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "aHvnnNh_DwNP",
        "outputId": "6131fe45-da06-4b92-b82a-8b3e0189b4e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"The square root of the current US president's age (78) multiplied by 132 is approximately 102.\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 117, 'candidates_token_count': 28, 'total_token_count': 145, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.046135395765304565}, id='run-a29bf725-d310-4643-9482-6ec223853c80-0', usage_metadata={'input_tokens': 117, 'output_tokens': 28, 'total_tokens': 145})"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm=llm, tools=[search_tool, calculator_tool], prompt=system_prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chapter2.5",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
