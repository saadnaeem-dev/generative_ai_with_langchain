"""
CorpDocs with Citations: A Corporate Documentation Pipeline with RAG and Source Attribution
This single file contains the complete code to run a documentation generation system
using LangChain, LangGraph, and Gradio. In addition to generating and refining documentation,
this pipeline now retrieves and attaches citations to the final output.

Workflow Overview:
1. Generate an initial project documentation draft from a user's request.
2. Analyze the draft for compliance with corporate standards.
3. If issues are detected, prompt for human expert feedback.
4. Finalize the documentation (integrating any feedback).
5. Retrieve and append citations to the final document.
6. Output the fully revised document with inline source citations.

Note: More details on performance measurement and observability will be covered in Chapter 8.
"""

import uuid                     # For generating unique session IDs.
import gradio as gr             # For building the interactive web interface.
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate
from typing_extensions import TypedDict  # For defining a structured state.
from langgraph.graph import StateGraph, START, END  # For managing our workflow.
from langgraph.checkpoint.memory import MemorySaver  # For state checkpointing.
from langchain_groq import ChatGroq

from chapter4.retriever import DocumentRetriever
from config import set_environment

set_environment()


system_prompt = (
    "You're a helpful AI assistant. Given a user question "
    "and some corporate document snippets, write a documentation. "
    "If none of the documents answers the question, "
    "mention that there's nothing relevant and then answer the question to the best of your knowledge."
    "\n\nHere are the corporate documents: "
    "{context}"
)

# Initialize the LangChain ChatGroq interface using the API key from environment variables.
chat_model = ChatGroq(
    model="deepseek-r1-distill-llama-70b",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)
retriever = DocumentRetriever()
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}"),
    ]
)
question_answer_chain = create_stuff_documents_chain(chat_model, prompt)
retrieval_chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=question_answer_chain)


# Define our application state. This state carries the documentation through each stage.
class State(TypedDict):
    doc_request: str       # The initial documentation prompt.
    initial_doc: str       # The draft document generated by GPT-4.
    compliance_report: str # Report from the compliance check.
    issues_detected: bool  # Flag indicating if any compliance issues were detected.
    human_feedback: str    # Feedback provided by a human expert.
    final_doc: str         # The finalized document (before citations are added).

# -------------------------------------------------------------------------------------------
# NODE: doc_generator
# Generates the initial documentation draft and runs a compliance check.
def doc_generator(state: State) -> State:
    """Generate initial documentation and perform compliance analysis."""
    # --- Step 1: Documentation Generation ---
    retrieval_chain.invoke([
        (
            "system",
            "You are a helpful assistant that translates English to French. Translate the user sentence.",
        ),
        ("human", "I love programming."),
    ])

    response = chat_model.invoke(
        [{
            "role": "user",
            "content": (
                f"Review the following project documentation for compliance with our corporate standards. "
                f"Return 'ISSUES FOUND' followed by any issues detected or 'NO ISSUES': {state['initial_doc']}"
            )
        }]
    )
    state["initial_doc"] = response.content

    # --- Step 2: Compliance Check ---
    compliance_check = chat_model.invoke(
        [{
            "role": "user",
            "content": (
                f"Review the following project documentation for compliance with our corporate standards. "
                f"Return 'ISSUES FOUND' followed by any issues detected or 'NO ISSUES': {state['initial_doc']}"
            )
        }]
    )
    result = compliance_check.choices[0].message.content
    if "ISSUES FOUND" in result:
        state["compliance_report"] = result.split("ISSUES FOUND", 1)[1].strip()
        state["issues_detected"] = True
    else:
        state["compliance_report"] = ""
        state["issues_detected"] = False

    return state

# -------------------------------------------------------------------------------------------
# NODE: human_feedback_handler
# Captures human expert feedback if compliance issues are found.
def human_feedback_handler(state: State) -> State:
    """Process human feedback to address compliance issues."""
    # Reset the issues flag after receiving feedback.
    state["issues_detected"] = False
    return state

# -------------------------------------------------------------------------------------------
# NODE: doc_finalizer
# Finalizes the documentation by incorporating human feedback if available.
def doc_finalizer(state: State) -> State:
    """Finalize documentation by integrating human feedback."""
    if "human_feedback" in state and state["human_feedback"]:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": (
                    f"Revise the following documentation to address these feedback points: {state['human_feedback']}\n"
                    f"Original Document: {state['initial_doc']}\n"
                    f"Always return the full revised document, even if no changes are needed."
                )
            }]
        )
        state["final_doc"] = response.choices[0].message.content
    else:
        state["final_doc"] = state["initial_doc"]
    return state

# -------------------------------------------------------------------------------------------
# NODE: citation_adder
# Retrieves and appends citations to the final document.
def citation_adder(state: State) -> State:
    """Add citations to the final document using simulated source retrieval."""
    # --- Step 5: Retrieve Citations ---
    # In a real application, you might query a vector database or API to fetch sources.
    # Here we simulate this with a list of dummy citation dictionaries.
    citations = [
        {"source": "Corporate Whitepaper 2023", "url": "https://corp.com/whitepaper2023", "text": "Insights into modern project documentation."},
        {"source": "Industry Report Q1", "url": "https://industryreports.com/q1", "text": "Benchmarking compliance best practices."}
    ]
    # --- Step 6: Append Citations ---
    # Format the citations as a markdown-style list and append to the final document.
    citation_text = "\n\nCitations:\n"
    for citation in citations:
        citation_text += f"- {citation['source']} ({citation['url']}): {citation['text']}\n"
    state["final_doc"] += citation_text
    return state

# -------------------------------------------------------------------------------------------
# CONDITIONAL TRANSITION FUNCTION
# Determines whether to ask for human feedback or proceed directly to finalization.
def compliance_check_condition(state: State) -> str:
    """Route to human feedback if compliance issues are detected; otherwise, finalize document."""
    if state["issues_detected"]:
        return "human_feedback_handler"
    else:
        return "doc_finalizer"

# -------------------------------------------------------------------------------------------
# GRAPH CONSTRUCTION: Assemble the nodes into a single workflow.
graph_builder = StateGraph(State)
graph_builder.add_node("doc_generator", doc_generator)
graph_builder.add_node("human_feedback_handler", human_feedback_handler)
graph_builder.add_node("doc_finalizer", doc_finalizer)
graph_builder.add_node("citation_adder", citation_adder)  # New node for adding citations.

# Define the workflow edges:
graph_builder.add_edge(START, "doc_generator")
graph_builder.add_conditional_edges(
    "doc_generator",
    compliance_check_condition,
    {
        "human_feedback_handler": "human_feedback_handler",  # If issues, ask for feedback.
        "doc_finalizer": "doc_finalizer"                    # Otherwise, finalize directly.
    }
)
graph_builder.add_edge("human_feedback_handler", "doc_finalizer")
# After finalizing, add citations before ending.
graph_builder.add_edge("doc_finalizer", "citation_adder")
graph_builder.add_edge("citation_adder", END)

# -------------------------------------------------------------------------------------------
# GRADIO INTERFACE: Build the interactive web UI.
CSS = """
.contain { display: flex; flex-direction: column; }
#component-0 { height: 100%; }
#chatbot { flex-grow: 1; overflow: auto;}
"""

with gr.Blocks(css=CSS, title="ðŸ“„ CorpDocs with Citations") as demo:
    memory = MemorySaver()
    graph = graph_builder.compile(
        checkpointer=memory,
        interrupt_before=["human_feedback_handler"]
    )

    gr.Markdown("""
    # ðŸ“„ CorpDocs with Citations
    
    CorpDocs is your corporate documentation assistant. This tool generates detailed project documentation,
    verifies compliance with corporate standards, and integrates human feedback when necessary. Finally,
    it retrieves and attaches source citations to the final document.
    
    **Workflow:**
    1. **Generate Documentation:** Create an initial draft.
    2. **Compliance Check:** Automatically review for adherence to corporate guidelines.
    3. **Human Feedback:** If issues are detected, provide corrective feedback.
    4. **Finalize Document:** Produce the revised document.
    5. **Add Citations:** Append source citations to the document.
    
    If you like this application, please give us a 5-star review on [Amazon](https://amzn.to/3X1xQbn)!
    """)

    chatbot = gr.Chatbot(
        show_copy_button=False,
        show_share_button=True,
        label="Documentation Assistant",
        elem_id="chatbot",
        type="tuples"
    )
    msg = gr.Textbox(
        placeholder="Enter your project documentation request...",
        container=False,
        scale=7
    )
    user_id = gr.State(None)
    state = gr.State(None)

    # -------------------------------------------------------------------------------------------
    # PROCESS REQUEST FUNCTION
    # Handles user input, updates the pipeline state, and streams responses to the UI.
    def process_request(message, history, state, user_id):
        if not user_id:
            user_id = str(uuid.uuid4())
        config = {"configurable": {"thread_id": user_id}}

        # If no state exists, initialize with the documentation request.
        if not state:
            state = {"doc_request": message}
            history = [(message, "Generating documentation...")]
        # If compliance issues were flagged, treat the input as human feedback.
        elif "issues_detected" in state and state["issues_detected"]:
            state["human_feedback"] = message
            graph.update_state(config=config, values=state)
            history.append((message, "Updating documentation based on feedback..."))
        yield history, state, user_id, None

        # Process the state through the workflow and stream updates.
        for event in graph.stream(None if "human_feedback" in state else state, config=config):
            state = graph.get_state(config=config).values
            if isinstance(event, dict):
                if "doc_generator" in event:
                    if event["doc_generator"]["issues_detected"]:
                        history.append((None, f"Compliance issues detected:\n{event['doc_generator']['compliance_report']}\n"
                                              "Please provide your feedback on how to resolve these issues."))
                    else:
                        history.append((None, event["doc_generator"]["initial_doc"]))
                elif "doc_finalizer" in event:
                    history.append((None, f"Final Document (pre-citations):\n\n{event['doc_finalizer']['final_doc']}"))
                elif "citation_adder" in event:
                    history.append((None, f"Final Document with Citations:\n\n{event['citation_adder']['final_doc']}"))
            yield history, state, user_id, None

    msg.submit(
        process_request,
        inputs=[msg, chatbot, state, user_id],
        outputs=[chatbot, state, user_id, msg],
        show_progress="hidden"
    )

    # -------------------------------------------------------------------------------------------
    # EXAMPLE BUTTONS: Provide preset documentation scenarios.
    with gr.Row():
        example_button1 = gr.Button("Example 1: New Product Launch")
        example_button2 = gr.Button("Example 2: Quarterly Report")
        example_button3 = gr.Button("Example 3: Security Audit Summary")

    def load_example(example_num):
        if example_num == 1:
            return "Generate documentation for a new product launch outlining objectives, timelines, and KPIs."
        elif example_num == 2:
            return "Generate a detailed quarterly report for the marketing department."
        elif example_num == 3:
            return "Generate a security audit summary for our IT infrastructure."
        else:
            return None

    example_button1.click(fn=load_example, inputs=[gr.Number(value=1, visible=False)], outputs=[msg], show_progress="hidden").then(
        process_request,
        inputs=[msg, chatbot, state, user_id],
        outputs=[chatbot, state, user_id, msg],
        show_progress="hidden"
    )
    example_button2.click(fn=load_example, inputs=[gr.Number(value=2, visible=False)], outputs=[msg], show_progress="hidden").then(
        process_request,
        inputs=[msg, chatbot, state, user_id],
        outputs=[chatbot, state, user_id, msg],
        show_progress="hidden"
    )
    example_button3.click(fn=load_example, inputs=[gr.Number(value=3, visible=False)], outputs=[msg], show_progress="hidden").then(
        process_request,
        inputs=[msg, chatbot, state, user_id],
        outputs=[chatbot, state, user_id, msg],
        show_progress="hidden"
    )

    refresh_button = gr.Button("ðŸ”„ Refresh")
    refresh_button.click(fn=lambda: None, inputs=[], outputs=[chatbot, state, user_id], js="() => {window.location.reload()}")

    gr.Markdown(
        """
        By using this application, you agree to OpenAI's [terms of use](https://openai.com/policies/row-terms-of-use/) and [privacy policy](https://openai.com/policies/row-privacy-policy/).
        """
    )


if __name__ == "__main__":
    # Launch the Gradio application.
    # For hot-reloading run from the terminal from the top-level directory of the repository like this:
    # > gradio chapter4/app.py
    # If you run from the chapter4/ you can set the PYTHONPATH, for example, in Linux and MacOS:
    # > PYTHONPATH=../ gradio app.py
    # Please make sure you are in the langchain_ai environment, for example by typing
    # conda activate langchain_ai
    demo.launch()


