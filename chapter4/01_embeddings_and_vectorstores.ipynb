{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8075668-ff7c-40cf-95ae-177553572049",
   "metadata": {},
   "source": [
    "**Make sure you load the API keys for cloud providers!**\n",
    "\n",
    "You can set your environment keys yourself or use a script. Please note that since keys are private, they are not included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b52dc1-406d-4376-9cf9-5f6353d436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the environment variables, the keys\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from config import set_environment\n",
    "# for the keys - as explained early in chapter 2\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e1a24-3ece-4313-af79-3a0e3233a03e",
   "metadata": {},
   "source": [
    "# Basic Embeddings Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c7144c-901a-4158-a29e-fee9f42e3b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n",
      "Dimensions per embedding: 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create embeddings for example sentences\n",
    "text1 = \"The cat sat on the mat\"\n",
    "text2 = \"A feline rested on the carpet\"\n",
    "text3 = \"Python is a programming language\"\n",
    "\n",
    "# Get embeddings using LangChain\n",
    "embeddings = embeddings_model.embed_documents([text1, text2, text3])\n",
    "\n",
    "# These similar sentences will have similar embeddings\n",
    "embedding1 = embeddings[0]  # Embedding for \"The cat sat on the mat\"\n",
    "embedding2 = embeddings[1]  # Embedding for \"A feline rested on the carpet\"\n",
    "embedding3 = embeddings[2]  # Embedding for \"Python is a programming language\"\n",
    "\n",
    "# Output shows number of documents and embedding dimensions\n",
    "print(f\"Number of documents: {len(embeddings)}\")\n",
    "print(f\"Dimensions per embedding: {len(embeddings[0])}\")\n",
    "# Typically 1536 dimensions with OpenAI's embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a038c-3d55-4ca0-9f85-962b509b2854",
   "metadata": {},
   "source": [
    "# Vector Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f8a67a-c9c3-4672-88f4-9d0d9d8aa076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found documents: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize with an embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create some sample documents with explicit IDs\n",
    "docs = [\n",
    "    Document(page_content=\"Content about language models\", metadata={\"id\": \"doc_1\"}),\n",
    "    Document(page_content=\"Information about vector databases\", metadata={\"id\": \"doc_2\"}),\n",
    "    Document(page_content=\"Details about retrieval systems\", metadata={\"id\": \"doc_3\"})\n",
    "]\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "\n",
    "# Add documents with explicit IDs\n",
    "vector_store.add_documents(docs)\n",
    "\n",
    "# Similarity Search with appropriate k value\n",
    "results = vector_store.similarity_search(\"How do language models work?\", k=2)\n",
    "\n",
    "# For MMR, adjust the parameters based on available documents\n",
    "found_docs = vector_store.similarity_search(\"retrieval\", k=1)\n",
    "print(f\"Found documents: {len(found_docs)}\")\n",
    "\n",
    "if len(remaining_docs) > 0:\n",
    "    mmr_results = vector_store.max_marginal_relevance_search(\n",
    "        \"retrieval systems\",\n",
    "        k=1,  # Only request what's available\n",
    "        fetch_k=1,  # Only fetch what's available\n",
    "        lambda_mult=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fe417-7cb4-4555-83ef-e6554732284e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
