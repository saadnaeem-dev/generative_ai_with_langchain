{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a37c58-eaaa-453e-af23-2f991cff6f14",
   "metadata": {},
   "source": [
    "**Make sure you load the API keys for cloud providers!**\n",
    "\n",
    "You can set your environment keys yourself or use a script. Please note that since keys are private, they are not included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01fa931-ca17-43b8-8fcc-62806d68b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the environment variables, the keys\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from config import set_environment\n",
    "# for the keys - as explained early in chapter 2\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c64cd3a-df6e-42c8-8249-84bbe3430266",
   "metadata": {},
   "source": [
    "# Basic RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45303b2-3ca1-462e-9e3a-3e62fdff2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For query transformation\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# For basic RAG implementation\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1. Load documents\n",
    "loader = JSONLoader(\n",
    "    file_path=\"knowledge_base.json\",\n",
    "    jq_schema=\".[].content\",  # This extracts the content field from each array item\n",
    "    text_content=True\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Convert to vectors\n",
    "embedder = OpenAIEmbeddings()\n",
    "embeddings = embedder.embed_documents([doc.page_content for doc in documents])\n",
    "\n",
    "# 3. Store in vector database\n",
    "vector_db = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "# 4. Retrieve similar docs\n",
    "query = \"What are the effects of climate change?\"\n",
    "results = vector_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e99cc4d-0b93-4b7e-88ef-e156b6f9d4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='6153c01c-db7c-40a3-9eaa-b49b270e8a20', metadata={'source': '/home/ben/generative_ai_with_langchain/chapter4/knowledge_base.json', 'seq_num': 1}, page_content=\"Transformer models were introduced in the paper 'Attention Is All You Need' by Vaswani et al. in 2017. The architecture relies on self-attention mechanisms rather than recurrent or convolutional neural networks. This design allows for more parallelization during training and better handling of long-range dependencies in text.\"), Document(id='131c5049-2858-4562-b331-c3492f92ed15', metadata={'source': '/home/ben/generative_ai_with_langchain/chapter4/knowledge_base.json', 'seq_num': 4}, page_content='Retrieval-Augmented Generation (RAG) combines a retrieval system with a text generator. The retriever fetches relevant documents from a knowledge base, and these documents are then provided as context to the generator. RAG models can be fine-tuned end-to-end and leverage large pre-trained models like BART or T5 for generation. This approach helps ground the generated text in factual information.'), Document(id='ae286760-8f31-40d4-aa10-c0698fc8c56b', metadata={'source': '/home/ben/generative_ai_with_langchain/chapter4/knowledge_base.json', 'seq_num': 3}, page_content='GPT (Generative Pre-trained Transformer) models are autoregressive language models that use transformer-based neural networks. Unlike BERT, which is bidirectional, GPT models are unidirectional and predict the next token based on previous tokens. The original GPT was introduced by OpenAI in 2018, followed by GPT-2 in 2019 and GPT-3 in 2020, each significantly larger than its predecessor.'), Document(id='81571e55-f3a0-4a24-981d-b98e125a2e76', metadata={'source': '/home/ben/generative_ai_with_langchain/chapter4/knowledge_base.json', 'seq_num': 2}, page_content='BERT (Bidirectional Encoder Representations from Transformers) was developed by Google AI Language team in 2018. It is pre-trained using masked language modeling and next sentence prediction tasks. BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.')]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bf112-227f-4fcc-ac69-cca48bb7cdf8",
   "metadata": {},
   "source": [
    "# KNN Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c39830-1c19-48bc-9fd0-da888d3b6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import KNNRetriever\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "retriever = KNNRetriever.from_documents(documents, OpenAIEmbeddings())\n",
    "results = retriever.invoke(\"query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ee8d7-332c-437c-b565-52da1b00cacc",
   "metadata": {},
   "source": [
    "# External Search API Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2988f2d-b014-438c-a685-a2816b248aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers.pubmed import PubMedRetriever\n",
    "\n",
    "retriever = PubMedRetriever()\n",
    "results = retriever.invoke(\"COVID research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950ee7c-9969-423b-8338-2f9bd5d2fe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
