{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "gQ2nlH7IbyZt",
      "metadata": {
        "id": "gQ2nlH7IbyZt"
      },
      "source": [
        "# Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "TnjThIoIbzLq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1737994654380,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "TnjThIoIbzLq",
        "outputId": "53d21f7a-c620-4a5b-f57a-0b6529acdc8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount of input messages: 1\n",
            "History length: 2\n",
            "Amount of input messages: 1\n",
            "History length: 4\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.language_models import FakeListChatModel\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain_core.messages import trim_messages, HumanMessage\n",
        "\n",
        "\n",
        "class PrintOutputCallback(BaseCallbackHandler):\n",
        "    def on_chat_model_start(self, serialized, messages, **kwargs):\n",
        "        print(f\"Amount of input messages: {len(messages)}\")\n",
        "\n",
        "\n",
        "sessions = {}\n",
        "handler = PrintOutputCallback()\n",
        "llm = FakeListChatModel(responses=[\"ai1\", \"ai2\", \"ai3\"])\n",
        "\n",
        "def get_session_history(session_id: str):\n",
        "    if session_id not in sessions:\n",
        "        sessions[session_id] = InMemoryChatMessageHistory()\n",
        "    return sessions[session_id]\n",
        "\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=1,\n",
        "    strategy=\"last\",\n",
        "    token_counter=len,\n",
        "    include_system=True,\n",
        "    start_on=\"human\",\n",
        ")\n",
        "\n",
        "raw_chain = trimmer | llm\n",
        "chain = RunnableWithMessageHistory(raw_chain, get_session_history)\n",
        "\n",
        "config = {\"callbacks\": [PrintOutputCallback()], \"configurable\": {\"session_id\": \"1\"}}\n",
        "_ = chain.invoke(\n",
        "    [HumanMessage(\"Hi!\")],\n",
        "    config=config,\n",
        ")\n",
        "print(f\"History length: {len(sessions['1'].messages)}\")\n",
        "\n",
        "_ = chain.invoke(\n",
        "    [HumanMessage(\"How are you?\")],\n",
        "    config=config,\n",
        ")\n",
        "print(f\"History length: {len(sessions['1'].messages)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "U4aVcUOzd_MN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1737993223355,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "U4aVcUOzd_MN",
        "outputId": "5277f297-e921-4770-87b4-8e75424161e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='ai1', additional_kwargs={}, response_metadata={}, id='run-61ec6b0b-6631-48c7-95b6-61da8ec7aca7-0'),\n",
              " HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='ai2', additional_kwargs={}, response_metadata={}, id='run-387c2f6c-209d-4de3-8cc4-fdb4afa88fe5-0')]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sessions[\"1\"].messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ZJ-AVSwWdf1l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 564,
          "status": "ok",
          "timestamp": 1737993218824,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "ZJ-AVSwWdf1l",
        "outputId": "7598d13e-5b88-4f3d-a0e7-7dc0702f8bf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmer.invoke(sessions[\"1\"].messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9WNcHwxkTMNI",
      "metadata": {
        "id": "9WNcHwxkTMNI"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessageGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import AIMessage\n",
        "from langgraph.graph import START, END\n",
        "\n",
        "\n",
        "def test_node(state):\n",
        "   # ignore the last message since it's an input one\n",
        "   print(f\"History length = {len(state[:-1])}\")\n",
        "   return [AIMessage(content=\"Hello!\")]\n",
        "\n",
        "builder = MessageGraph()\n",
        "builder.add_node(\"test_node\", test_node)\n",
        "builder.add_edge(START, \"test_node\")\n",
        "builder.add_edge(\"test_node\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fPBE54uwQ-Wa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 783,
          "status": "ok",
          "timestamp": 1738044658050,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "fPBE54uwQ-Wa",
        "outputId": "a7633a90-e87d-486d-cad9-353ca2efdf16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "History length = 0\n",
            "History length = 0\n",
            "History length = 2\n"
          ]
        }
      ],
      "source": [
        "_ = graph.invoke([HumanMessage(content=\"test\")], config={\"configurable\": {\"thread_id\": \"thread-a\"}})\n",
        "_ = graph.invoke([HumanMessage(content=\"test\")], config={\"configurable\": {\"thread_id\": \"thread-b\"}})\n",
        "_ = graph.invoke([HumanMessage(content=\"test\")], config={\"configurable\": {\"thread_id\": \"thread-a\"}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0Fu4w9hjbdjY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1850,
          "status": "ok",
          "timestamp": 1738044690501,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "0Fu4w9hjbdjY",
        "outputId": "16b0f88e-efe9-41c8-82eb-a4166744abfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1eff8dbc-fe59-662a-8004-064ebb341150\n",
            "1eff8dbc-fe58-6450-8003-2ee2b7ffac5e\n",
            "1eff8dbc-fe56-68b2-8002-c5562269bb46\n",
            "1eff8dbc-fe48-6f50-8001-710b65f78d1f\n",
            "1eff8dbc-fe3b-6864-8000-d5f811d92d2f\n",
            "1eff8dbc-fe29-6768-bfff-2f0d41677e7c\n"
          ]
        }
      ],
      "source": [
        "checkpoints = list(memory.list(config={\"configurable\": {\"thread_id\": \"thread-a\"}}))\n",
        "for check_point in checkpoints:\n",
        "  print(check_point.config[\"configurable\"][\"checkpoint_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "VEXrQKJndJg9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1738044690501,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "VEXrQKJndJg9",
        "outputId": "db01d9ec-b518-4bfe-905c-7247956c1beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "History length = 0\n"
          ]
        }
      ],
      "source": [
        "checkpoint_id = checkpoints[-1].config[\"configurable\"][\"checkpoint_id\"]\n",
        "_ = graph.invoke(\n",
        "    [HumanMessage(content=\"test\")],\n",
        "    config={\"configurable\": {\"thread_id\": \"thread-a\", \"checkpoint_id\": checkpoint_id}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "HUMp34J5hzYB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1738044691796,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "HUMp34J5hzYB",
        "outputId": "1f7657a6-4115-4d86-fc22-f3b7ae554f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "History length = 2\n"
          ]
        }
      ],
      "source": [
        "checkpoint_id = checkpoints[-3].config[\"configurable\"][\"checkpoint_id\"]\n",
        "_ = graph.invoke(\n",
        "    [HumanMessage(content=\"test\")],\n",
        "    config={\"configurable\": {\"thread_id\": \"thread-a\", \"checkpoint_id\": checkpoint_id}})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chapter 2.3",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
