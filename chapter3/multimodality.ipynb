{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ZNqTDFzOoJ8x",
      "metadata": {
        "id": "ZNqTDFzOoJ8x"
      },
      "source": [
        "# Multimodality"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Ma4vohEQAZl",
      "metadata": {
        "id": "1Ma4vohEQAZl"
      },
      "source": [
        "Let's copy an image from a public bucket with examples first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ItgZXeHjoPTa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3159,
          "status": "ok",
          "timestamp": 1737794591180,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "ItgZXeHjoPTa",
        "outputId": "3f97fe8f-3f84-4762-c64d-75441f36bea5"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://cloud-samples-data/generative-ai/image/boats.jpeg ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wXEKl9maQERu",
      "metadata": {
        "id": "wXEKl9maQERu"
      },
      "source": [
        "We can send it as bytes and ask the model to describe it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VSDe7rFcpZWW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 544,
          "status": "ok",
          "timestamp": 1737795534092,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "VSDe7rFcpZWW",
        "outputId": "c509c9f6-8d28-4ce9-bfaa-fa116705a8c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image shows a calm body of water with two boats anchored in the foreground and a city skyline in the background. The first boat is a pontoon boat, with a dark blue stripe, a white deck, and a green Bimini top. The second boat is a smaller, open motorboat. In the background, there's a large stone bridge with multiple arches, leading to a cityscape with a mix of modern high-rise buildings and older structures, including a building with two distinctive domes. The sky is overcast, contributing to the subdued lighting in the scene.\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "llm = ChatVertexAI(model_name=\"gemini-2.0-flash-001\")\n",
        "\n",
        "with open(\"boats.jpeg\", 'rb') as image_file:\n",
        "  image_bytes = image_file.read()\n",
        "  base64_bytes = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "\n",
        "prompt = [\n",
        "    {\"type\": \"text\", \"text\": \"Describe the image: \"},\n",
        "    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_bytes}\"}},\n",
        "]\n",
        "\n",
        "response = llm.invoke([HumanMessage(content=prompt)])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lkWiIAArQHo1",
      "metadata": {
        "id": "lkWiIAArQHo1"
      },
      "source": [
        "We can also do the same with videos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "m4wVlTBL6-07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7863,
          "status": "ok",
          "timestamp": 1737799636005,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "m4wVlTBL6-07",
        "outputId": "129e5526-ca01-4a85-902f-326fecdc0365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The video shows the Los Angeles Zoo with zoo employees setting up different enclosures for animals to interact with Google Photos cameras in order to give people unique perspectives of the animals that they've never seen before. The animals in the video include giraffes, elephants, tigers, and otters. It also showcases how Google Photos automatically backs up photos and lets users share them via social media.\n"
          ]
        }
      ],
      "source": [
        "video_uri = \"gs://cloud-samples-data/generative-ai/video/animals.mp4\"\n",
        "prompt = [\n",
        "    {\"type\": \"text\", \"text\": \"Describe the video in a few sentences.\"},\n",
        "    {\"type\": \"media\", \"file_uri\": video_uri, \"mime_type\": \"video/mp4\"},\n",
        "]\n",
        "\n",
        "response = llm.invoke([HumanMessage(content=prompt)])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z_rNrbbKQJrR",
      "metadata": {
        "id": "z_rNrbbKQJrR"
      },
      "source": [
        "Also we can define an offset (a piece of video to be processed by the model):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "IsYi4JoU8NQt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4857,
          "status": "ok",
          "timestamp": 1737799872055,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "IsYi4JoU8NQt",
        "outputId": "a5be71de-4d99-4ffd-b680-6970772ae9ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The video is about what would happen if animals in the real world were given technology like the characters in Zootopia. The video shows Nick Wilde taking a selfie, followed by a shot of the Los Angeles Zoo and an interview with Rico Farmer, Brand and Experiential Marketing Manager. He says theyâ€™re at the Los Angeles Zoo, letting animals talk.\n"
          ]
        }
      ],
      "source": [
        "offset_hint = {\n",
        "            \"start_offset\": {\"seconds\": 10},\n",
        "            \"end_offset\": {\"seconds\": 20},\n",
        "        }\n",
        "prompt = [\n",
        "    {\"type\": \"text\", \"text\": \"Describe the video in a few sentences.\"},\n",
        "    {\"type\": \"media\", \"file_uri\": video_uri, \"mime_type\": \"video/mp4\", \"video_metadata\": offset_hint},\n",
        "]\n",
        "\n",
        "response = llm.invoke([HumanMessage(content=prompt)])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I3P_FmF6ZJ71",
      "metadata": {
        "id": "I3P_FmF6ZJ71"
      },
      "source": [
        "We can also use prompt substitution to pass bytes to the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "-gKK3e94oK70",
      "metadata": {
        "id": "-gKK3e94oK70"
      },
      "outputs": [],
      "source": [
        "image_uri = \"gs://cloud-samples-data/generative-ai/image/boats.jpeg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bQ48gO_fYwJh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 541,
          "status": "ok",
          "timestamp": 1737800223798,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "bQ48gO_fYwJh",
        "outputId": "38d56499-11ec-499c-8970-91eeb61997bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content=[{'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,test-url'}}], additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"user\",\n",
        "     [{\"type\": \"image_url\",\n",
        "       \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_bytes_str}\"},\n",
        "       }])]\n",
        ")\n",
        "prompt.invoke({\"image_bytes_str\": \"test-url\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chapter 2.3",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
